{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install imbalanced-learn\n",
    "%pip install xgboost\n",
    "%pip install onnxmltools\n",
    "%pip install skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance,XGBClassifier\n",
    "import xgboost as xgb\n",
    "import onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to generate data for clinical analysis\n",
    "def generate_obesity_data_v2(n_samples=1000):\n",
    "    # Variables (features) for the dataset\n",
    "    bmi = np.random.normal(32, 5, n_samples).clip(18.5, 50) # Body Mass Index (BMI) (kg/m^2) (normal range: 18.5 - 24.9)\n",
    "    ldl = np.random.normal(140 + (bmi - 25) * 2, 30, n_samples).clip(50, 250) # Low Density Lipoprotein (LDL) (mg/dL) (normal range: < 100)\n",
    "    triglycerides = np.random.normal(180 + (bmi - 25) * 3, 50, n_samples).clip(50, 500) # Triglycerides (mg/dL) (normal range: < 150)\n",
    "    glucose = np.random.choice([np.nan, *np.random.normal(110, 15, n_samples).clip(70, 200)], n_samples) # Glucose (mg/dL) (normal range: 70 - 100)\n",
    "    hb1ac = np.random.choice([np.nan, *np.random.normal(5.5, 1, n_samples).clip(4, 10)], n_samples) # Hemoglobin A1c (%) (normal range: < 5.7)\n",
    "    \n",
    "    # Parámetros adicionales (opcionales)\n",
    "    pcr = np.random.choice([np.nan, *np.random.normal(1.5, 0.5, n_samples).clip(0.5, 10)], n_samples) # Reactive Protein C (PCR) (mg/dL) (normal range: < 1)\n",
    "    insuline = np.random.choice([np.nan, *np.random.normal(15, 5, n_samples).clip(2, 50)], n_samples)  # Insuline (uU/mL) (normal range: 2 - 25)\n",
    "    ast = np.random.normal(20, 10, n_samples).clip(0, 100)  # Hepatic enzymes (AST) (normal range: < 40)\n",
    "    alt = np.random.normal(25, 10, n_samples).clip(0, 100)  # Hepatic enzymes (ALT) (normal range: < 40)\n",
    "    leptin = np.random.choice([np.nan, *np.random.normal(25, 5, n_samples).clip(10, 50)], n_samples)  # Leptin (ng/mL) (normal range: 10 - 25)\n",
    "\n",
    "    # Add noise to the label\n",
    "    noise = np.random.binomial(1, 0.00, n_samples)  # 5% of noise\n",
    "\n",
    "    # Label based on obesity criteria (BMI > 30, LDL > 160, Triglycerides > 200)\n",
    "    label = ((bmi > 30) & (ldl > 160) & (triglycerides > 200)).astype(int) # 1: Obese, 0: Not obese\n",
    "    label = (label + noise) % 2  # Add noise\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"bmi\": bmi,\n",
    "        \"ldl\": ldl,\n",
    "        \"triglycerides\": triglycerides,\n",
    "        \"glucose\": glucose,\n",
    "        \"hb1ac\": hb1ac,\n",
    "        \"pcr\": pcr,\n",
    "        \"insuline\": insuline,\n",
    "        \"ast\": ast,\n",
    "        \"alt\": alt,\n",
    "        \"leptin\": leptin,\n",
    "        \"label\": label\n",
    "    }) # Return the dataset as a DataFrame object (Pandas)\n",
    "\n",
    "df_obesity = generate_obesity_data_v2(n_samples=1000) # Generate the dataset with 1000 samples\n",
    "df_obesity.head() # Show the first 5 samples of the dataset (DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\") # Create the imputer object (mean strategy) \n",
    "X = df_obesity.drop(columns=\"label\")   # Features (X) \n",
    "X_imputed = imputer.fit_transform(X) # Impute the missing values in the features (X) \n",
    "y = df_obesity[\"label\"]  # Label (y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the fine-tunning file for Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo JSONL para el fine-tuning\n",
    "def prepare_jsonl(df, output_file):\n",
    "    \"\"\"\n",
    "    Convierte un DataFrame a un archivo JSONL compatible con OpenAI para fine-tuning.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            # Creates the prompt\n",
    "            prompt = (\n",
    "                f\"Valores clínicos:\\n\"\n",
    "                f\"BMI: {row['bmi']}, LDL: {row['ldl']}, Triglicéridos: {row['triglycerides']}, \"\n",
    "                f\"Glucosa: {row['glucose']}, HbA1c: {row['hb1ac']}, \"\n",
    "                f\"PCR: {row['pcr']}, Insulina: {row['insuline']}, AST: {row['ast']}, ALT: {row['alt']}, Leptina: {row['leptin']}.\\n\"\n",
    "                f\"¿Tiene obesidad?\"\n",
    "            )\n",
    "            # Create the completion (answer)\n",
    "            completion = \" Sí\" if row[\"label\"] == 1 else \" No\"\n",
    "            # Write the JSON line to the file\n",
    "            json_line = {\"prompt\": prompt, \"completion\": completion}\n",
    "            f.write(f\"{json_line}\\n\")\n",
    "\n",
    "# Generate the JSONL file for fine-tuning\n",
    "output_file = \"obesity_finetuning_data.jsonl\"\n",
    "prepare_jsonl(df_obesity, output_file)\n",
    "print(f\"Archivo JSONL generado: {output_file}\")\n",
    "\n",
    "# Generate the JSONL file for fine-tuning\n",
    "output_file = \"obesity_finetuning_data.jsonl\"\n",
    "prepare_jsonl(df_obesity, output_file)\n",
    "print(f\"Archivo JSONL generado: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42) \n",
    "X_train_renamed = pd.DataFrame(X_train, columns=[f\"f{i}\" for i in range(X_train.shape[1])]) # Rename the columns of the training set (X_train)\n",
    "\n",
    "\n",
    "# Calculate the scale_pos_weight parameter for XGBoost \n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Create the XGBoost model \n",
    "xgb_model = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42, eval_metric=\"logloss\")\n",
    "# Train the model \n",
    "xgb_model.fit(X_train_renamed, y_train)\n",
    "\n",
    "# Plot the feature importance (Evaluation of the model) \n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb)) # Accuracy of the model (before optimization) \n",
    "print(classification_report(y_test, y_pred_xgb)) # Classification report of the model (before optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance (Evaluation of the model)\n",
    "xgb_model.get_booster().feature_names = df_obesity.drop(columns=\"label\").columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(10, 8)) # Create the figure \n",
    "plot_importance(xgb_model, importance_type=\"weight\") # Plot the feature importance (weight)\n",
    "plt.title(\"Importancia de las características - XGBoost\") # Title of the plot\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert the XGBoost model to ONNX format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Test dataset (X_test, y_test)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "# Model parameters (XGBoost)\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "}\n",
    "\n",
    "# Training the model (XGBoost)\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Prediction (XGBoost)\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the model (XGBoost) - Test dataset (X_test, y_test) (after optimization)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_binary))\n",
    "# Classification report of the model (after optimization) \n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"eta\": 0.1,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8\n",
    "} # Model parameters (XGBoost)\n",
    "\n",
    "# Cross-validation (XGBoost) - 5 folds\n",
    "cv_results = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=100,\n",
    "    nfold=5, \n",
    "    metrics=[\"logloss\"], \n",
    "    as_pandas=True,\n",
    "    seed=42\n",
    ") # Results of the cross-validation (XGBoost)\n",
    "\n",
    "# Show the results of the cross-validation (XGBoost) \n",
    "print(cv_results)\n",
    "# Show the mean logloss of the cross-validation (XGBoost)\n",
    "print(\"Mean Logloss:\", cv_results[\"test-logloss-mean\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Set feature names to match the DataFrame columns\n",
    "xgb_model.get_booster().feature_names = X_train_renamed.columns.tolist()\n",
    "\n",
    "# Define the initial type of the model\n",
    "initial_type = [(\"float_input\", FloatTensorType([None, X_train_renamed.shape[1]]))]\n",
    "\n",
    "# Convert the XGBoost model to ONNX\n",
    "onnx_model = onnxmltools.convert_xgboost(xgb_model, initial_types=initial_type)\n",
    "\n",
    "# Save the ONNX model\n",
    "with open(\"xgboost_obesity_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "# Print the message\n",
    "print(\"Modelo ONNX generado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
